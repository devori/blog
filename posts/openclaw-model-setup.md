---
title: "OpenClaw 모델 연결 가이드: 무료로 시작해서 똑똑하게 확장하기"
date: "2026-02-10"
excerpt: "Gemini 무료 티어를 메인으로 쓰면서, 필요할 때만 Claude Opus로 전환하는 스마트한 AI 비서 세팅법"
---

AI 비서를 본격적으로 사용하기 시작하면 피할 수 없는 고민이 있다. 바로 **'성능'**과 **'비용'**의 균형이다.

Claude Opus 같은 최고급 모델을 쓰면 똑똑하긴 한데 지갑이 아프고, 무료 모델만 고집하자니 가끔 "이게 최선이야?" 싶은 답변에 아쉬움이 남는다. 그렇다고 매번 수동으로 모델을 바꿔가며 쓰기엔 너무 번거롭다.

OpenClaw의 **Failover(자동 전환)** 기능은 이 고민을 깔끔하게 해결한다. 평소엔 무료 모델로 대부분의 작업을 처리하고, 정말 필요한 순간에만 프리미엄 모델이 자동으로 등판하는 구조다.

## 왜 모델을 여러 개 연결해야 할까?

단일 모델만 사용하면 예상치 못한 문제에 부딪힌다.

**무료 모델만 쓸 때:**
- Rate Limit에 걸리면 갑자기 응답 불가
- 복잡한 코딩이나 긴 문서 작업에서 품질 저하
- "잠시 후 다시 시도해주세요" 메시지와의 싸움

**유료 모델만 쓸 때:**
- "오늘 날씨 어때?" 같은 단순 질문에도 비용 발생
- 월말 청구서를 보고 놀라는 경험
- 비용 걱정에 AI 사용을 주저하게 됨

여러 모델을 연결하면 두 마리 토끼를 다 잡을 수 있다. 일상적인 대화는 무료로 처리하고, 진짜 어려운 문제에만 프리미엄 모델의 힘을 빌린다.

## Gemini Free Tier: 생각보다 넉넉하다

Google Gemini API의 무료 티어는 개인 사용자에게 꽤 관대하다.

- **분당 요청 (RPM)**: 15회 — 1분에 15번 질문 가능
- **일일 요청 (RPD)**: 1,500회 — 하루 1,500번 질문 가능
- **분당 토큰 (TPM)**: 100만 — 엄청 긴 문서도 처리 가능

하루 1,500번이면 아침부터 밤까지 쉬지 않고 대화해도 남는다. 현실적으로 혼자 쓰기엔 충분한 양이다.

다만 주의할 점이 있다. **분당 15회** 제한은 생각보다 빡빡할 수 있다. 특히 코딩 작업처럼 AI가 파일을 읽고, 수정하고, 테스트하는 과정에서 도구를 연속으로 호출하면 순식간에 한도에 도달한다. 이럴 때 Failover가 빛을 발한다.

## Claude Opus: 든든한 백업이자 비장의 무기

Gemini가 막혔을 때, 또는 정말 어려운 문제를 만났을 때 등판할 Claude Opus 4.5.

**가격:**
- Input: $5/MTok (100만 토큰당 5달러)
- Output: $25/MTok (100만 토큰당 25달러)

언뜻 보면 비싸 보이지만, Fallback 용도로만 쓰면 실제 비용은 미미하다. 한 달에 Opus가 10번 정도 등판한다고 치면? 몇천 원 수준이다.

그리고 Opus는 확실히 다르다. 복잡한 코드 리팩토링, 미묘한 뉘앙스가 필요한 글쓰기, 여러 조건을 동시에 고려해야 하는 분석 작업에서 "아, 역시 비싼 모델이 다르구나" 싶은 순간이 온다.

## 설정 방법: 3분이면 끝

OpenClaw 설정 파일을 열고 `model` 섹션만 수정하면 된다.

**파일 위치:** `~/.openclaw/openclaw.json`

```json
{
  "agents": {
    "defaults": {
      "model": {
        "primary": "google/gemini-3-flash-preview",
        "fallbacks": ["anthropic/claude-opus-4-5"]
      }
    }
  }
}
```

핵심은 두 가지다:
- `primary`: 평소에 사용할 기본 모델
- `fallbacks`: primary가 실패했을 때 순서대로 시도할 백업 모델들 (배열)

Fallback을 여러 개 지정할 수도 있다:

```json
"fallbacks": ["anthropic/claude-sonnet-4", "anthropic/claude-opus-4-5"]
```

이렇게 하면 Gemini → Sonnet → Opus 순으로 시도한다. 비용 효율을 극대화하는 전략이다.

## 작동 원리: 사용자는 신경 쓸 게 없다

설정만 해두면 나머지는 OpenClaw가 알아서 처리한다.

1. 평소에는 **Gemini Flash**가 모든 요청을 처리
2. Rate Limit 도달, API 오류, 또는 일시적 장애 발생 시
3. **자동으로 다음 Fallback 모델로 전환**
4. 원래 모델이 복구되면 다시 원래 모델 사용

전환 과정이 매끄러워서 사용자 입장에서는 "응답이 살짝 느려졌나?" 정도로만 느껴진다. 갑자기 막히거나 에러가 뜨는 일 없이, 항상 어떤 형태로든 응답을 받을 수 있다.

## 실전 토큰 최적화 팁

Failover 설정만으로도 충분히 효율적이지만, 몇 가지 습관을 들이면 비용을 더 아낄 수 있다.

### 1. Compaction 기능 활용하기

대화가 길어지면 컨텍스트가 쌓이고, 컨텍스트가 쌓이면 토큰 소비가 늘어난다. OpenClaw의 Compaction 기능은 오래된 대화 내용을 자동으로 요약해서 컨텍스트 크기를 관리한다.

```json
"compaction": {
  "mode": "safeguard"
}
```

`safeguard` 모드가 기본값인데, 컨텍스트가 한계에 가까워지면 자동으로 압축을 시작한다. 대부분의 경우 이 설정으로 충분하다.

### 2. 대화 주제가 바뀌면 새 세션 시작하기

"아까 그거 말고 다른 얘기 할게"라면서 같은 세션에서 전혀 다른 주제로 넘어가면, 이전 대화 내용이 계속 컨텍스트에 남아서 토큰을 잡아먹는다.

주제가 완전히 바뀌면 `/clear` 명령어로 세션을 정리하거나, 새 세션을 시작하는 게 좋다.

### 3. Prompt Caching 활용하기 (Claude)

Claude API를 사용할 때 동일한 시스템 프롬프트는 캐싱되어 재사용된다. 첫 요청에서 캐시를 쓰고, 이후 요청에서는 캐시를 읽기만 하면 되니 비용이 **최대 90%까지 절감**된다.

OpenClaw는 기본적으로 5분 캐시(`short`)를 사용한다. 더 긴 작업이 예상되면 1시간 캐시(`long`)로 설정할 수도 있다:

```json
"models": {
  "anthropic/claude-opus-4-5": {
    "params": { "cacheRetention": "long" }
  }
}
```

### 4. 구체적으로 요청하기

"이거 고쳐줘"보다 "3번째 함수의 null 체크가 빠진 것 같아. 추가해줘"가 낫다. AI가 추측하는 시간(=토큰)을 아낄 수 있고, 원하는 결과물을 한 번에 얻을 확률도 높아진다.

## 한 달 사용 후기

이 설정으로 한 달을 보낸 결과:

- **Gemini 사용량**: 일 평균 200~300회 요청
- **Opus 전환 횟수**: 총 15회 정도 (대부분 Rate Limit)
- **월 비용**: 약 $2 (Opus 사용분)

사실상 **무료에 가까운 비용**으로 AI 비서를 풀타임 운영하고 있다. 가끔 복잡한 작업에서 Opus가 등판하면 "역시 든든하다" 싶고, 평소에는 Gemini가 충분히 빠르고 똑똑하다.

비용 걱정 없이 AI 비서를 마음껏 활용해보자. 설정에 3분, 효과는 매일 체감할 수 있다.
